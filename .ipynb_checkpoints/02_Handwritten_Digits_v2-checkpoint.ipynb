{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing Handwritten Digits using Scikit-Learn\n",
    "\n",
    "MNIST dataset: https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "![alt text][img]\n",
    "\n",
    "[img]: https://i.imgur.com/2xVHT7a.png \"not the best handwriting\"\n",
    "\n",
    "* 28x28 (784 pixels total) images of handwritten digits\n",
    "* each image has a label 0-9\n",
    "* ~~70,000~~ 42,000 total images & labels\n",
    "* our goal is to correctly guess the label when we can only see pixel data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets # broken - mldata.org is down. Using local csv file for now (sorry!)\n",
    "import pandas as pd\n",
    "from IPython.display import display # pretty tables\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# mnist = fetch_mldata('MNIST original') # this ridiculously convenient function is broken ;_;\n",
    "mnist = pd.read_csv('../MNIST/train.csv') # only using train, because test has no labels\n",
    "\n",
    "print(mnist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Rundown\n",
    "\n",
    "\"Machine Learning is the science (and art) of programming computers so they can *learn from data.*\"\n",
    "\n",
    "* Aurélien Géron, *Hands-On Machine Learning with Scikit-Learn & Tensorflow*\n",
    "\n",
    "**Some useful resources**\n",
    "\n",
    "* Scikit-Learn's introduction to machine learning: http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "* MIT OpenCourseWare: https://www.youtube.com/watch?v=h0e2HAPTGF4\n",
    "* kaggle - datasets and ML competitions: https://www.kaggle.com/datasets\n",
    "\n",
    "**Example: Spam-filter**\n",
    "\n",
    "* Learns to flag spam from given examples of spam emails and regular, \"ham\", emails\n",
    "* This set of example emails is called the *training set*\n",
    "* Each email in the training set is called an *instance*\n",
    "* Each instance contains *data* (contents of the email) and a *target* ('spam' or 'ham')\n",
    "* Each point of data within an instance is a *feature*\n",
    "* For training purposes, we separate the data and target\n",
    "\n",
    "**Math notation**\n",
    "\n",
    "* Uppercase Bold = Matrices\n",
    "    * e.g. $\\mathbf{A}$  \n",
    "* Lowercase Bold = Vectors  \n",
    "    * e.g. $\\mathbf{a}$\n",
    "* Italics = Scalars  \n",
    "    * e.g. $a$\n",
    "* Rows are indexed by subscript, Columns by superscript\n",
    "\n",
    "$\\mathbf{X}$ is a matrix containing the data portion of our dataset (no labels)\n",
    "\n",
    "* $\\mathbf{X}$ has $n$ rows (instances) and $m$ columns (features)\n",
    "\n",
    "The i-th row of the matrix, $\\mathbf{x}_i$, is one instance in our dataset.\n",
    "\n",
    "The j-th element of the i-th row is the value of one feature for a given instance, denoted $x_i^j$\n",
    "\n",
    "$\\mathbf{y}$ is the target vector containing a label for each instance \n",
    "\n",
    "The i-th element of the target vector is a label for a single instance, $y_i$\n",
    "\n",
    "* Sometimes our data doesn't have labels. When we have labels for training, it's called *Supervised Learning*. When we don't, it's *Unsupervised Learning.* We'll stick to Supervised Learning for now.\n",
    "\n",
    "Our model is a function, $h$, which takes in an instance, $\\mathbf{x}_i$, and gives us a *Predicted Label*, $\\hat{y_i}$\n",
    "\n",
    "$$\\large{ h(\\mathbf{x}_i) = \\hat{y_i} }$$\n",
    "\n",
    "if $\\hat{y_i} = y_i$, then our model guessed the label perfectly for the i-th instance\n",
    "\n",
    "We can also run our model on all instanes in our dataset in one go:\n",
    "\n",
    "$$\\large{ h(\\mathbf{X}) = \\mathbf{\\hat{y}} }$$\n",
    "\n",
    "In practice, we split the given dataset into a *Training Set* and *Test Set*, so we can evaluate our models after we train them.\n",
    "*It is very important that we do not let our models see the test data during training!* Our goal is not to memorize our data, but to create a model capable of classifyig data it has never seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate data and target labels\n",
    "\n",
    "* Pandas dataframe/series documentation: https://pandas.pydata.org/pandas-docs/stable/dsintro.html\n",
    "* iloc takes in positional index (ints) and returns a dataframe or series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (42000, 784)\n",
      "target shape:  (42000,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "data = mnist.iloc[:,1:] # returns a numpy array\n",
    "target = mnist.iloc[:,0]\n",
    "# 784 features (pixels), 42,000 instances (images)\n",
    "print(\"data shape: \", data.shape)\n",
    "print(\"target shape: \", target.shape)\n",
    "print(type(data))\n",
    "print(type(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = data.values # converts to numpy array\n",
    "y = target.values\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "# 37,000 for training, 5,000 for testing\n",
    "X_train, X_test = X[:37000], X[37000:]\n",
    "y_train, y_test = y[:37000], y[37000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display A Random Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing image  31244\n",
      "Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAByNJREFUeJzt3T+oT38cx/F7RdzEpX6L6CYGysxdhAwMkpKUlAFlEMmEiUJd3fKva1CyGGQx3Egm8rcMZhkMuHGlDNeNuNdv+a3n/cW97vW7r8djfd1z71meneHzPd/b/uPHjzYgz7TJvgFgcogfQokfQokfQokfQokfQokfQokfQokfQk2f4L/n44Tw57X/zA958kMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UOo6ZN9A/xZo6Oj5f7169cx/f7Xr1+Xe39/f+P27du38tqenp5y37t3b7n39vY2bocPHy6vPX78eLnPmTOn3P8PPPkhlPghlPghlPghlPghlPghlKO+v8CnT5/KvdVx3ePHjxu3W7dulddevny53Fvp7Ows94ULF/727160aFG5f//+vdwXL17cuJ07d668dtasWeV+6tSpcv8/8OSHUOKHUOKHUOKHUOKHUOKHUOKHUM75x8GHDx/K/eLFi+V+9uzZch8eHi73pUuXNm7VWXdbW1vbnj17xrQvWLCg3Lu6usp9LFq9EjxtWvOzrdU5fwJPfgglfgglfgglfgglfgglfgglfgjV/uPHj4n8exP6x35FqzPj+/fvN247duwor509e3a5r169utyPHDlS7tVZ+ty5c8tr/2bv378v96dPn5b71q1bG7eNGzeW1166dKncW31+YpK1/8wPefJDKPFDKPFDKPFDKPFDKPFDKPFDKO/z/6e9vT4affnyZeM2c+bM8totW7aU+/nz58t9qhoZGSn3Q4cOlfuNGzfKvTrnb/X/CubPn1/uU4EnP4QSP4QSP4QSP4QSP4QSP4QSP4TyPv84+Pz5c7lX3x/f1tbW1tHRMZ6381d5+/Zt47Z27dry2o8fP5Z7T09Pue/evbtxmz59Sn/Exfv8QDPxQyjxQyjxQyjxQyjxQyhHfZQGBwfL/cSJE+V+9erVxm3z5s3ltadPny736l+Th3PUBzQTP4QSP4QSP4QSP4QSP4QSP4Ryzj/FjY6OlvubN2/Kfc2aNeXe6rXbbdu2NW5Xrlwpr231KjSNnPMDzcQPocQPocQPocQPocQPocQPoab09xenGBoaatyq9+nb2lr/G+wVK1aU+507d8p9+fLl5c7k8eSHUOKHUOKHUOKHUOKHUOKHUOKHUN7nnwDDw8PlPjAwUO5nzpwp94cPHzZuL168KK8dq4MHD5b7smXLGrcNGzaU1y5ZsuS37gnv8wMF8UMo8UMo8UMo8UMo8UMo8UMo5/wT4MGDB+W+bt26Mf3+lStXNm6tvnd/3759Y/rb//zzT7nfvXu3cevp6Smv7evrK/fu7u5yD+acH2gmfgglfgglfgglfgglfgjlqG8CvHr1qtwvXbpU7uvXry/36qiwo6OjvHYyPXr0qNz3799f7vfu3Sv3efPm/eotTRWO+oBm4odQ4odQ4odQ4odQ4odQ4odQzvmZNN+/fy/3Vp9v6OzsLPf+/v5fvqcpwjk/0Ez8EEr8EEr8EEr8EEr8EEr8EGr6ZN8AuUZHR8v9yZMn5X706NHxvJ04nvwQSvwQSvwQSvwQSvwQSvwQSvwQyjn/f0ZGRsq9OpOeMWPGeN9OhOfPn5d7e3v9WvqCBQvG83biePJDKPFDKPFDKPFDKPFDKPFDqJiv7m71+mhfX1+5r1q1qnHr7u7+rXtK8O7du8Zt+/bt5bVdXV3lfu3atd+6pwC+uhtoJn4IJX4IJX4IJX4IJX4IJX4IFfNKb6vPMwwODpb7q1evGrepfM4/PDxc7rdv3y73Xbt2NW4HDhwor+3p6Sl3xsaTH0KJH0KJH0KJH0KJH0KJH0KJH0LFvM/fytDQULmvXr26cbtw4UJ57Zo1a37rnsbD169fy73V12f39vaW+82bN8u9+p6EnTt3ltfOmTOn3GnkfX6gmfghlPghlPghlPghlPghlPghlHP+n9Tf39+4HTt2rLy21f8M+JO+fPlS7t++fSv3U6dOlfumTZvKfd68eY3btGmePX+Ic36gmfghlPghlPghlPghlPghlPghlHP+cTAwMFDu169fL/dnz56V+40bN8p927ZtjdvJkyfLa7u6usp95syZ5c5fyTk/0Ez8EEr8EEr8EEr8EEr8EMpRH0w9jvqAZuKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUOKHUNMn+O/91HvGwJ/nyQ+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+hxA+h/gUOrEX8Jnsf9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0, X_train.shape[0])\n",
    "print('Showing image ', rand_index)\n",
    "plt.imshow(X_train[rand_index].reshape(28,28), cmap='Greys')\n",
    "# cmap keyword: defines colorspace of image\n",
    "# https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "plt.axis('off')\n",
    "print('Label: ', target[rand_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier\n",
    "\n",
    "Easy starting point. Output is True or False (in the class, or not in the class)\n",
    "\n",
    "In this case, we'll recognize whether a digit is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 4 0 0 7 3 5 3]\n",
      "[False False False False False False False False  True False]\n"
     ]
    }
   ],
   "source": [
    "# First, we need to restructure our labels (no need to modify the data itself)\n",
    "y_train_5 = (y_train == 5) \n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "# let's take a peak at our new training labels\n",
    "print(y_train[0:10])   # multiclass\n",
    "print(y_train_5[0:10]) # binary\n",
    "# now, instead of digits 0-9, we have 0's for 'not 5' and 1's for '5' - Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "* list of classification models: http://scikit-learn.org/stable/supervised_learning.html\n",
    "* To start, we will use a SGDClassifier http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "    - SGD is the name of the training algorithm, \"Stochastic Gradient Descent.\" We'll learn much more about Gradient Descent soon!\n",
    "    - This is a linear model, meaning it finds linear boundaries between classes (remember, our classes to start out with are 'five' and 'not five')\n",
    "    - The main reason I've selected this model is that it's simplicity allows for much faster training on our high-dimensional dataset. The trade-off is that it will be less accurate than more complex models.\n",
    "* To train models in sklearn, we only have to call the fit() function and pass in our data and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# there are many parameters we can set here, but they all have default values, so we can safely leave this blank for now\n",
    "classifier = SGDClassifier() \n",
    "classifier.fit(X_train, y_train_5) # This line alone trains the model. We need to pass in the data and labels\n",
    "# We'll implement our own fit() function soon!\n",
    "\n",
    "# ignore the warning - the default parameters for this class work fine for our purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index  860 :\n",
      "Predicted Label:  [False]\n",
      "Actual Label (binary):  False\n",
      "Actual Label (multi-class):  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0, 5000)\n",
    "# once the model has been trained, we only have to call the predict() function!\n",
    "prediction = classifier.predict([X_test[rand_index]]) # pass in a random row from X_test\n",
    "\n",
    "print(\"Index \", rand_index, \":\")\n",
    "print(\"Predicted Label: \", prediction)\n",
    "print(\"Actual Label (binary): \", y_test_5[rand_index])\n",
    "print(\"Actual Label (multi-class): \", y_test[rand_index])\n",
    "\n",
    "plt.imshow(X_test[rand_index].reshape(28,28), cmap='Greys')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, it worked!! Or maybe it didn't. Either way, one example from the test set doesn't tell us much, and we isolated 5,000 instances for a reason. Fortunately, we can run predict() on the entire test set and get back an array of 5,000 predicted labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_5_pred = classifier.predict(X_test) # pass in the entire test set\n",
    "score = accuracy_score(y_test_5, y_test_5_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a great score! Guess our simple model did pretty well on it's own? Not necessarily.\n",
    "\n",
    "Just because we are doing a binary classification task doesn't mean that our data is split evenly into two classes! In this case, only 10% of the samples are in the 'five' class, and the rest are 'not five', so a \"dumb\" model that just spits out [ False ] Every time would have *90% accuracy!*\n",
    "\n",
    "This is called *Label Imbalance*\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "We can't rely on a single metric to evaluate our model. The *Confusion Matrix* is a useful tool for evaluation, because it shows us how many instances are classified correctly and incorrectly for both of our classes. More precisely,\n",
    "\n",
    "$$\\text{confusion matrix} = \\begin{bmatrix} \\text{True Negative} & \\text{False Positive} \\\\ \\text{False Negative} & \\text{True Positive} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4507   78]\n",
      " [  95  320]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mx = confusion_matrix(y_test_5, y_test_5_pred)\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall\n",
    "\n",
    "Two more useful values we can extract from the confusion matrix are *Precision* and *Recall.*\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "* Precision is the proportion of instances that were correctly labeled as 'True' out of all the 'True' predictions\n",
    "    - How many of our selected items were classified correctly?\n",
    "    - Higher precision => fewer false positives\n",
    "* Recall is the proportion of instances that were correctly labeled as 'True' out of all the instances that actually are 'True'\n",
    "    - How many of the total relevant items did we get?\n",
    "    - Higher recall => fewer false negatives\n",
    "    \n",
    "More formally,\n",
    "\n",
    "$\\text{Precision} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Positive}}}$\n",
    "\n",
    "$\\text{Recall} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Negative}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8040201005025126\n",
      "Recall:  0.7710843373493976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test_5, y_test_5_pred)\n",
    "recall = recall_score(y_test_5, y_test_5_pred)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_clf = SGDClassifier()\n",
    "multi_clf.fit(X_train, y_train) # same data, different labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>368</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>437</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>236</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>126</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>440</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>78</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9\n",
       "0  500    0    0    0    0    0    2    1   17    0\n",
       "1    0  516    1    0    1    1    1    2   40    1\n",
       "2   11    2  368    6    3    0    2    9   63    1\n",
       "3    5    3   28  405    0    7    3   10   67    2\n",
       "4    3    3    2    0  437    2    1   10   54    9\n",
       "5    6    5    5   14    5  236    6    6  126    6\n",
       "6    6    2    5    0    5    2  440    0   34    0\n",
       "7    1    1    5    0    3    1    0  489    3    3\n",
       "8    4    7    4    2    0    5    1    1  461    0\n",
       "9    6    0    4    1   14    3    0  143   78  252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_pred = multi_clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "conf_mx = confusion_matrix(y_test, y_test_pred) # what does the confusion matrix look like for multiclass predictions?\n",
    "\n",
    "print(acc) # How is this accuracy score different from the binary accuracy score? \n",
    "           # Is it a better or worse measure of performance?\n",
    "display(pd.DataFrame(conf_mx)) # convert to dataframe so it prints with indices, use display() to make it pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAAmCAYAAAAsspvsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAcpJREFUeJzt3Mtu1EAQBdB+ODMJBAgg8f8/GF4CEkBhWETyVLdsxAKRRZ2zqumqtlvWzJU3ST2dTgWAXNpTHwCA/0/4AyQk/AESEv4ACQl/gISEP0BCwh8gIeEPkJDwB0hoeeoD7Km1rn96/K5cD70X5e1aH0PvMqyXUspF6B3Km1C/HuaW8jzsuVnrHtYfe6/CnpdDr5er0LsO65fjveqztW7lGPaMc3Ffr0tYvxjmWulhLtSljnPhYx/Wf033fQi9c93rz+m+38Pc2Ov1bq1r/RHWv05n+hLq+zD3eZir9VvofTrvaR+nufP1e/uwuf647/32GdrtNHe7Pdfvhrkanm3rQ6u0tlNPc3vXqNPrWVu259o0V/vO3PIP5kKvjl/H8ezzNeLZw746P7PQa4c/zMVePNPh7+bacZwbrnHcXp/3tfCznZ/FcI35OcV9sZ7PvtOrV9PcsO80/vh3ePMHSEj4AyQk/AESqv6rJ0A+3vwBEhL+AAkJf4CEhD9AQsIfICHhD5CQ8AdISPgDJCT8ARIS/gAJCX+AhIQ/QELCHyAh4Q+QkPAHSEj4AyQk/AESEv4ACQl/gISEP0BCwh8gIeEPkJDwB0joN2q+IkdtXZdzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show color map for reference\n",
    "plt.imshow(np.arange(0, 1, 0.01).reshape(1,-1), cmap = 'gnuplot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(X_train[np.random.randint(0, 5000)].reshape(28,28), cmap='Greys')\n",
    "\n",
    "# Display confusion matrix as an image\n",
    "plt.imshow(conf_mx, cmap = 'gnuplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall for Multiclass Predictions\n",
    "\n",
    "//TODO: explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg):  0.8673139960308578\n",
      "Recall (weighted avg):  0.8208\n",
      "Precision (simple avg):  0.8652434503004003\n",
      "Recall (simple avg):  0.8151653093429477\n"
     ]
    }
   ],
   "source": [
    "precision_weighted = precision_score(y_test, y_test_pred, average=\"weighted\")\n",
    "recall_weighted = recall_score(y_test, y_test_pred, average=\"weighted\")\n",
    "precision_macro = precision_score(y_test, y_test_pred, average=\"macro\")\n",
    "recall_macro = recall_score(y_test, y_test_pred, average=\"macro\")\n",
    "\n",
    "print(\"Precision (weighted avg): \", precision_weighted)\n",
    "print(\"Recall (weighted avg): \", recall_weighted) \n",
    "print(\"Precision (simple avg): \", precision_macro)\n",
    "print(\"Recall (simple avg): \", recall_macro) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
