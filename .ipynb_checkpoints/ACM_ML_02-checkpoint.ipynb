{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing Handwritten Digits using Scikit-Learn\n",
    "\n",
    "MNIST dataset: https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "* 28x28 (784 pixels total) images of handwritten digits\n",
    "* each image has a label 0-9\n",
    "* 70,000 total images & labels\n",
    "* our goal is to correctly guess the label when we can only see pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing image  16379\n",
      "Label:  2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x208800829e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print random image from the dataset\n",
    "rand_index = np.random.randint(0, 70000)\n",
    "data = mnist['data']\n",
    "target = mnist['target']\n",
    "print('Showing image ', rand_index)\n",
    "plt.imshow(data[rand_index].reshape(28,28), cmap='Greys')\n",
    "plt.axis('off')\n",
    "print('Label: ', target[rand_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Rundown\n",
    "\n",
    "\"Machine Learning is the science (and art) of programming computers so they can *learn from data.*\"\n",
    "\n",
    "* Aurélien Géron, *Hands-On Machine Learning with Scikit-Learn & Tensorflow*\n",
    "\n",
    "**Some useful resources**\n",
    "\n",
    "* Scikit-Learn's introduction to machine learning: http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "* MIT OpenCourseWare: https://www.youtube.com/watch?v=h0e2HAPTGF4\n",
    "* kaggle - website with lots of datasets and frequent ML competitions! https://www.kaggle.com/datasets\n",
    "\n",
    "**Example: Spam-filter**\n",
    "\n",
    "* Learns to flag spam from given examples of spam emails and regular, \"ham\", emails\n",
    "* This set of example emails is called the *training set*\n",
    "* Each email in the training set is called an *instance*\n",
    "* Each instance contains *data* (contents of the email) and a *target* ('spam' or 'ham')\n",
    "* Each point of data within an instance is a *feature*\n",
    "* For training purposes, we separate the data and target\n",
    "\n",
    "**Math notation**\n",
    "\n",
    "* Uppercase Bold denotes matrices\n",
    "* lowercase bold denotes vectors\n",
    "* Italics denotes scalars\n",
    "\n",
    "We denote data portion of our dataset (no labels) as a matrix, $\\mathbf{X}$\n",
    "\n",
    "* $\\mathbf{X}$ has $n$ rows (instances) and $m$ columns (features)\n",
    "\n",
    "The i-th row of the matrix is an instance, $\\mathbf{x}_i$\n",
    "\n",
    "The j-th element of the i-th row is the value of one feature for a given instance, denoted $x_{i,j}$\n",
    "\n",
    "The target vector contains a label for each instance. It's denoted $\\mathbf{y}$\n",
    "\n",
    "The i-th element of the target vector is a label for a single instance, $y_i$\n",
    "\n",
    "* Sometimes our data doesn't have labels. When we have labels for training, it's called *Supervised Learning*. When we don't, it's *Unsupervised Learning.* We'll stick to Supervised Learning for now.\n",
    "* In practice, we split the given dataset into a *Training Set* and *Test Set*, so we can evaluate our models after we train them.\n",
    "* It is *very important* that we do not let our models see the test data during training! Our goal is not to memorize the training data, but to create a model capable of classifyig new data.\n",
    "\n",
    "Our model is a function, $h$, which takes in an instance, $\\mathbf{x}_i$, and gives us a predicted label, $\\hat{y_i}$\n",
    "\n",
    "$$h(\\mathbf{x}_i) = \\hat{y_i}$$\n",
    "\n",
    "if $\\hat{y_i} = y_i$, then our model guessed the label perfectly for the i-th instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "X = mnist['data']\n",
    "y = mnist['target']\n",
    "# 784 features (pixels), 70,000 instances (images)\n",
    "print(X.shape, y.shape)\n",
    "# 60,000 for training, 10,000 for testing\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier\n",
    "\n",
    "Easy starting point. Output is True or False (in the class, or not in the class)\n",
    "\n",
    "In this case, we'll recognize whether a digit is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to restructure our labels\n",
    "y_train_5 = (y_train == 5) \n",
    "y_test_5 = (y_test == 5)\n",
    "# now, instead of digits 0-9, we have 0's for 'not 5' and 1's for '5' - Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "* list of classification models: http://scikit-learn.org/stable/supervised_learning.html\n",
    "* To start, we will use a SGDClassifier http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "    - SGD is the name of the training algorithm, \"Stochastic Gradient Descent.\" We'll learn much more about Gradient Descent algorithms soon!\n",
    "    - This is a linear model, meaning it finds linear boundaries between classes (remember, our classes to start out with are 'five' and 'not five')\n",
    "    - The main reason I've selected this model is that it's simplicity allows for much faster training on our high-dimensional dataset. The trade-off is that it will be less accurate than more complex models.\n",
    "* To train models in sklearn, we only have to call the fit() function and pass in our data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "classifier = SGDClassifier() # there are many parameters, but they all have default values, so we can safely leave this blank\n",
    "classifier.fit(X_train, y_train_5) # This line alone trains the model. \n",
    "# We'll see how we would implement a fit() function of our own soon!\n",
    "\n",
    "# ignore the warning - the default parameters for this class work fine for our purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model has been trained, let's make a prediction. We'll feed in a random digit and see if it guesses correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample  4875 :\n",
      "Predicted Label:  [False]\n",
      "Actual Label (binary):  False\n",
      "Actual Label (multi-class):  4.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20880079048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0, 10000)\n",
    "prediction = classifier.predict([X_test[rand_index]])\n",
    "print(\"Sample \", rand_index, \":\")\n",
    "print(\"Predicted Label: \", prediction)\n",
    "print(\"Actual Label (binary): \", y_test_5[rand_index])\n",
    "print(\"Actual Label (multi-class): \", y_test[rand_index])\n",
    "plt.imshow(X_test[rand_index].reshape(28,28), cmap='Greys')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, it worked!! Or maybe it didn't. Either way, one example from the test set doesn't tell us much, and we isolated 10,000 instances for a reason. Fortunately, we can run predict() on the entire test set and get back an array of 10,000 predicted labels. Using that, we can really evaluate how effective our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_5_pred = classifier.predict(X_test)\n",
    "score = accuracy_score(y_test_5, y_test_5_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a great score! Guess our simple model did pretty well on it's own? Not quite.\n",
    "\n",
    "Just because we are doing a binary classification task doesn't mean that our data is split evenly into two classes! In this case, only 10% of the samples are in the 'five' class, and the rest are 'not five', *so a model that spits out [ False ] Every time would have 90% accuracy!*\n",
    "\n",
    "We can't rely on a single metric to evaluate our model. We have 97% precision, but at what *recall*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
