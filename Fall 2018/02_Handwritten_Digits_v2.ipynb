{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recognizing Handwritten Digits using Scikit-Learn\n",
    "\n",
    "MNIST dataset: https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "![alt text][img]\n",
    "\n",
    "[img]: https://i.imgur.com/2xVHT7a.png \"not the best handwriting\"\n",
    "\n",
    "* 28x28 (784 pixels total) images of handwritten digits\n",
    "* each image has a label 0-9\n",
    "* ~~70,000~~ 42,000 total images & labels\n",
    "* our goal is to correctly guess the label when we can only see pixel data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning Rundown\n",
    "\n",
    "\"Machine Learning is the science (and art) of programming computers so they can *learn from data.*\"\n",
    "\n",
    "* Aurélien Géron, *Hands-On Machine Learning with Scikit-Learn & Tensorflow*\n",
    "\n",
    "**Some useful resources**\n",
    "\n",
    "* Scikit-Learn's introduction to machine learning: http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "* MIT OpenCourseWare: https://www.youtube.com/watch?v=h0e2HAPTGF4\n",
    "* kaggle - datasets and ML competitions: https://www.kaggle.com/datasets\n",
    "\n",
    "**Example: Spam-filter**\n",
    "\n",
    "* Learns to flag spam from given examples of spam emails and regular, \"ham\", emails\n",
    "* This set of example emails is called the *training set*\n",
    "* Each email in the training set is called an *instance*\n",
    "* Each instance contains *data* (contents of the email) and a *target* ('spam' or 'ham')\n",
    "* Each point of data within an instance is a *feature*\n",
    "* For training purposes, we separate the data and target\n",
    "\n",
    "**Math notation**\n",
    "\n",
    "* Uppercase Bold = Matrices\n",
    "    * e.g. $\\mathbf{A}$  \n",
    "* Lowercase Bold = Vectors  \n",
    "    * e.g. $\\mathbf{a}$\n",
    "* Italics = Scalars  \n",
    "    * e.g. $a$\n",
    "* Rows are indexed by subscript, Columns by superscript\n",
    "\n",
    "$\\mathbf{X}$ is a matrix containing the data portion of our dataset (no labels)\n",
    "\n",
    "* $\\mathbf{X}$ has $n$ rows (instances) and $m$ columns (features)\n",
    "\n",
    "The i-th row of the matrix, $\\mathbf{x}_i$, is one instance in our dataset.\n",
    "\n",
    "The j-th element of the i-th row is the value of one feature for a given instance, denoted $x_i^j$\n",
    "\n",
    "$\\mathbf{y}$ is the target vector containing a label for each instance \n",
    "\n",
    "The i-th element of the target vector is a label for a single instance, $y_i$\n",
    "\n",
    "* Sometimes our data doesn't have labels. When we have labels for training, it's called *Supervised Learning*. When we don't, it's *Unsupervised Learning.* We'll stick to Supervised Learning for now.\n",
    "\n",
    "Our model is a function, $h$, which takes in an instance, $\\mathbf{x}_i$, and gives us a *Predicted Label*, $\\hat{y_i}$\n",
    "\n",
    "$$\\large{ h(\\mathbf{x}_i) = \\hat{y_i} }$$\n",
    "\n",
    "if $\\hat{y_i} = y_i$, then our model guessed the label perfectly for the i-th instance\n",
    "\n",
    "We can also run our model on all instanes in our dataset in one go:\n",
    "\n",
    "$$\\large{ h(\\mathbf{X}) = \\mathbf{\\hat{y}} }$$\n",
    "\n",
    "In practice, we split the given dataset into a *Training Set* and *Test Set*, so we can evaluate our models after we train them.\n",
    "*It is very important that we do not let our models see the test data during training!* Our goal is not to memorize our data, but to create a model capable of classifyig data it has never seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fetch the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt     # pretty pictures\n",
    "from keras.datasets import mnist    # our dataset\n",
    "from IPython.display import display # pretty tables\n",
    "\n",
    "# The load_data() method provided here separates data and labels, and does the test/train split for us. Convenient!\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits.data.shape\n",
    "\n",
    "plt.imshow(digits.data[0].reshape((8,8)), cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the Data\n",
    "\n",
    "Our data is not in the exact format we want. We will use the reshape() method from numpy to fix this transform our data from 3D arrays to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# we want to preserve the # of rows, but collapse the last two dimensions into one\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Display A Random Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing image  34093  from training set\n",
      "Label:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0, X_train.shape[0])\n",
    "print('Showing image ', rand_index, ' from training set')\n",
    "plt.imshow(X_train[rand_index].reshape(28,28), cmap='Greys') # reshape the image back to a 2d array for display\n",
    "# cmap keyword: defines colorspace of image\n",
    "# https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "#plt.axis('off')\n",
    "print('Label: ', y_train[rand_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Binary Classifier\n",
    "\n",
    "Easy starting point. Output is True or False (in the class, or not in the class)\n",
    "\n",
    "In this case, we'll recognize whether a digit is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "[ True False False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "# First, we need to restructure our labels (no need to modify the data itself)\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "# let's take a peak at our new training labels\n",
    "print(y_train[0:10])   # multiclass\n",
    "print(y_train_5[0:10]) # binary\n",
    "# now, instead of digits 0-9, we have 0's for 'not 5' and 1's for '5' - Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "* list of classification models: http://scikit-learn.org/stable/supervised_learning.html\n",
    "* To start, we will use a SGDClassifier http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "    - SGD is the name of the training algorithm, \"Stochastic Gradient Descent.\" We'll learn much more about Gradient Descent soon!\n",
    "    - This is a linear model, meaning it finds linear boundaries between classes (remember, our classes to start out with are 'five' and 'not five')\n",
    "    - The main reason I've selected this model is that it's simplicity allows for much faster training on our high-dimensional dataset. The trade-off is that it will be less accurate than more complex models.\n",
    "* To train models in sklearn, we only have to call the fit() function and pass in our data and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# there are many parameters we can set here, but they all have default values, so we can safely leave this blank for now\n",
    "classifier = SGDClassifier() \n",
    "classifier.fit(X_train, y_train_5) # This line alone trains the model. We need to pass in the data and labels\n",
    "# We'll implement our own fit() function soon!\n",
    "\n",
    "# ignore the warning - the default parameters for this class work fine for our purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Making a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index  3469 :\n",
      "Predicted Label:  [False]\n",
      "Actual Label (binary):  False\n",
      "Actual Label (multi-class):  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0, 5000)\n",
    "# once the model has been trained, we only have to call the predict() function!\n",
    "prediction = classifier.predict([X_test[rand_index]]) # pass in a random row from X_test\n",
    "\n",
    "print(\"Index \", rand_index, \":\")\n",
    "print(\"Predicted Label: \", prediction)\n",
    "print(\"Actual Label (binary): \", y_test_5[rand_index])\n",
    "print(\"Actual Label (multi-class): \", y_test[rand_index])\n",
    "\n",
    "plt.imshow(X_test[rand_index].reshape(28,28), cmap='Greys')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Wow, it worked!! Or maybe it didn't. Either way, one example from the test set doesn't tell us much, and we isolated 5,000 instances for a reason. Fortunately, we can run predict() on the entire test set and get back an array of 5,000 predicted labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_5_pred = classifier.predict(X_test) # pass in the entire test set\n",
    "score = accuracy_score(y_test_5, y_test_5_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Wow, that's a great score! Guess our simple model did pretty well on it's own? Not necessarily.\n",
    "\n",
    "Just because we are doing a binary classification task doesn't mean that our data is split evenly into two classes! In this case, only 10% of the samples are in the 'five' class, and the rest are 'not five', so a \"dumb\" model that just spits out [ False ] Every time would have *90% accuracy!*\n",
    "\n",
    "This kind of situation is called *Label Imbalance*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "We can't rely on a single metric to evaluate our model. The *Confusion Matrix* is a useful tool for evaluation, because it shows us how many instances are classified correctly and incorrectly for both of our classes. More precisely,\n",
    "\n",
    "$$\\text{confusion matrix} = \\begin{bmatrix} \\text{True Negative} & \\text{False Positive} \\\\ \\text{False Negative} & \\text{True Positive} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8871  237]\n",
      " [ 151  741]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mx = confusion_matrix(y_test_5, y_test_5_pred)\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Precision and Recall\n",
    "\n",
    "Two more useful values we can extract from the confusion matrix are *Precision* and *Recall.*\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "* Precision is the proportion of instances that were correctly labeled as 'True' out of all the 'True' predictions\n",
    "    - How many of our selected items were classified correctly?\n",
    "    - Higher precision => fewer false positives\n",
    "* Recall is the proportion of instances that were correctly labeled as 'True' out of all the instances that actually are 'True'\n",
    "    - How many of the total relevant items did we get?\n",
    "    - Higher recall => fewer false negatives\n",
    "    \n",
    "More formally,\n",
    "\n",
    "$\\text{Precision} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Positive}}}$\n",
    "\n",
    "$\\text{Recall} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Negative}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.7576687116564417\n",
      "Recall:  0.8307174887892377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test_5, y_test_5_pred)\n",
    "recall = recall_score(y_test_5, y_test_5_pred)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_clf = SGDClassifier()\n",
    "multi_clf.fit(X_train, y_train) # same data, different labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accuracy, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8526\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>939</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1069</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>864</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>839</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>931</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>753</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>831</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>954</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>236</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>97</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1    2    3    4    5    6    7    8    9\n",
       "0  939     0    4    4    0    5    4    2   22    0\n",
       "1    0  1069    7    1    0    1    3    2   51    1\n",
       "2    4     5  864   22   16    5   12    9   91    4\n",
       "3    1     1   49  839    2   46    1   18   51    2\n",
       "4    0     0    6    5  931    1    2   11   14   12\n",
       "5    8     2    4   23   21  753   10   11   58    2\n",
       "6   11     4   25    1   23   40  831    1   22    0\n",
       "7    5     3   25    5    4    1    1  954   18   12\n",
       "8    1     5   15   14   15   38    4   19  862    1\n",
       "9   10     9    7   12  236   17    0  137   97  484"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_pred = multi_clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "conf_mx = confusion_matrix(y_test, y_test_pred) # what does the confusion matrix look like for multiclass predictions?\n",
    "\n",
    "print(acc) # How is this accuracy score different from the binary accuracy score? \n",
    "           # Is it a better or worse measure of performance?\n",
    "display(pd.DataFrame(conf_mx)) # convert to dataframe so it prints with indices, use display() to make it pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAAmCAYAAAAsspvsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAcpJREFUeJzt3Mtu1EAQBdB+ODMJBAgg8f8/GF4CEkBhWETyVLdsxAKRRZ2zqumqtlvWzJU3ST2dTgWAXNpTHwCA/0/4AyQk/AESEv4ACQl/gISEP0BCwh8gIeEPkJDwB0hoeeoD7Km1rn96/K5cD70X5e1aH0PvMqyXUspF6B3Km1C/HuaW8jzsuVnrHtYfe6/CnpdDr5er0LsO65fjveqztW7lGPaMc3Ffr0tYvxjmWulhLtSljnPhYx/Wf033fQi9c93rz+m+38Pc2Ov1bq1r/RHWv05n+hLq+zD3eZir9VvofTrvaR+nufP1e/uwuf647/32GdrtNHe7Pdfvhrkanm3rQ6u0tlNPc3vXqNPrWVu259o0V/vO3PIP5kKvjl/H8ezzNeLZw746P7PQa4c/zMVePNPh7+bacZwbrnHcXp/3tfCznZ/FcI35OcV9sZ7PvtOrV9PcsO80/vh3ePMHSEj4AyQk/AESqv6rJ0A+3vwBEhL+AAkJf4CEhD9AQsIfICHhD5CQ8AdISPgDJCT8ARIS/gAJCX+AhIQ/QELCHyAh4Q+QkPAHSEj4AyQk/AESEv4ACQl/gISEP0BCwh8gIeEPkJDwB0joN2q+IkdtXZdzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show color map for reference\n",
    "plt.imshow(np.arange(0, 1, 0.01).reshape(1,-1), cmap = 'gnuplot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Display confusion matrix as an image\n",
    "plt.imshow(conf_mx, cmap = 'gnuplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Precision and Recall for Multiclass Predictions\n",
    "\n",
    "**TODO:** explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "precision_weighted = precision_score(y_test, y_test_pred, average=\"weighted\")\n",
    "recall_weighted = recall_score(y_test, y_test_pred, average=\"weighted\")\n",
    "precision_macro = precision_score(y_test, y_test_pred, average=\"macro\")\n",
    "recall_macro = recall_score(y_test, y_test_pred, average=\"macro\")\n",
    "\n",
    "print(\"Precision (weighted avg): \", precision_weighted)\n",
    "print(\"Recall (weighted avg): \", recall_weighted)\n",
    "print(\"Precision (simple avg): \", precision_macro)\n",
    "print(\"Recall (simple avg): \", recall_macro)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
