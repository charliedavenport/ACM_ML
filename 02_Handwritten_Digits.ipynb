{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing Handwritten Digits using Scikit-Learn\n",
    "\n",
    "MNIST dataset: https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "* 28x28 (784 pixels total) images of handwritten digits\n",
    "* each image has a label 0-9\n",
    "* 70,000 total images & labels\n",
    "* our goal is to correctly guess the label when we can only see pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing image  35297\n",
      "Label:  5.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2287b2c27f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print random image from the dataset\n",
    "rand_index = np.random.randint(0, 70000)\n",
    "data = mnist['data']\n",
    "target = mnist['target']\n",
    "print('Showing image ', rand_index)\n",
    "plt.imshow(data[rand_index].reshape(28,28), cmap='Greys')\n",
    "plt.axis('off')\n",
    "print('Label: ', target[rand_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Rundown\n",
    "\n",
    "\"Machine Learning is the science (and art) of programming computers so they can *learn from data.*\"\n",
    "\n",
    "* Aurélien Géron, *Hands-On Machine Learning with Scikit-Learn & Tensorflow*\n",
    "\n",
    "**Some useful resources**\n",
    "\n",
    "* Scikit-Learn's introduction to machine learning: http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "* MIT OpenCourseWare: https://www.youtube.com/watch?v=h0e2HAPTGF4\n",
    "* kaggle - datasets and ML competitions: https://www.kaggle.com/datasets\n",
    "\n",
    "**Example: Spam-filter**\n",
    "\n",
    "* Learns to flag spam from given examples of spam emails and regular, \"ham\", emails\n",
    "* This set of example emails is called the *training set*\n",
    "* Each email in the training set is called an *instance*\n",
    "* Each instance contains *data* (contents of the email) and a *target* ('spam' or 'ham')\n",
    "* Each point of data within an instance is a *feature*\n",
    "* For training purposes, we separate the data and target\n",
    "\n",
    "**Math notation**\n",
    "\n",
    "* Uppercase Bold = matrices\n",
    "* lowercase bold = vectors\n",
    "* Italics = scalars\n",
    "\n",
    "$\\mathbf{X}$ is a matrix containing the data portion of our dataset (no labels)\n",
    "\n",
    "* $\\mathbf{X}$ has $n$ rows (instances) and $m$ columns (features)\n",
    "\n",
    "The i-th row of the matrix, $\\mathbf{x}_i$, is one instance in our dataset.\n",
    "\n",
    "The j-th element of the i-th row is the value of one feature for a given instance, denoted $x_{i,j}$\n",
    "\n",
    "$\\mathbf{y}$ is the target vector containing a label for each instance \n",
    "\n",
    "The i-th element of the target vector is a label for a single instance, $y_i$\n",
    "\n",
    "* Sometimes our data doesn't have labels. When we have labels for training, it's called *Supervised Learning*. When we don't, it's *Unsupervised Learning.* We'll stick to Supervised Learning for now.\n",
    "\n",
    "Our model is a function, $h$, which takes in an instance, $\\mathbf{x}_i$, and gives us a *Predicted Label*, $\\hat{y_i}$\n",
    "\n",
    "$$\\large{ h(\\mathbf{x}_i) = \\hat{y_i} }$$\n",
    "\n",
    "if $\\hat{y_i} = y_i$, then our model guessed the label perfectly for the i-th instance\n",
    "\n",
    "We can also run our model on all instanes in our dataset in one go:\n",
    "\n",
    "$$\\large{ h(\\mathbf{X}) = \\mathbf{\\hat{y}} }$$\n",
    "\n",
    "* In practice, we split the given dataset into a *Training Set* and *Test Set*, so we can evaluate our models after we train them.\n",
    "* *It is very important that we do not let our models see the test data during training!* Our goal is not to memorize the training data, but to create a model capable of classifyig new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "X = mnist['data']\n",
    "y = mnist['target']\n",
    "# 784 features (pixels), 70,000 instances (images)\n",
    "print(X.shape, y.shape)\n",
    "# 60,000 for training, 10,000 for testing\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier\n",
    "\n",
    "Easy starting point. Output is True or False (in the class, or not in the class)\n",
    "\n",
    "In this case, we'll recognize whether a digit is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to restructure our labels\n",
    "y_train_5 = (y_train == 5) \n",
    "y_test_5 = (y_test == 5)\n",
    "# now, instead of digits 0-9, we have 0's for 'not 5' and 1's for '5' - Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "* list of classification models: http://scikit-learn.org/stable/supervised_learning.html\n",
    "* To start, we will use a SGDClassifier http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "    - SGD is the name of the training algorithm, \"Stochastic Gradient Descent.\" We'll learn much more about Gradient Descent algorithms soon!\n",
    "    - This is a linear model, meaning it finds linear boundaries between classes (remember, our classes to start out with are 'five' and 'not five')\n",
    "    - The main reason I've selected this model is that it's simplicity allows for much faster training on our high-dimensional dataset. The trade-off is that it will be less accurate than more complex models.\n",
    "* To train models in sklearn, we only have to call the fit() function and pass in our data and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie\\Anaconda2\\envs\\tf_gpu\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# there are many parameters we can set here, but they all have default values, so we can safely leave this blank\n",
    "classifier = SGDClassifier() \n",
    "classifier.fit(X_train, y_train_5) # This line alone trains the model. \n",
    "# We'll go over how to implement our own fit() function soon!\n",
    "\n",
    "# ignore the warning - the default parameters for this class work fine for our purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model has been trained, let's make a prediction. We'll feed in a random digit and see if it guesses correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample  4469 :\n",
      "Predicted Label:  [False]\n",
      "Actual Label (binary):  False\n",
      "Actual Label (multi-class):  4.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2280204d358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0, 10000)\n",
    "prediction = classifier.predict([X_test[rand_index]])\n",
    "print(\"Sample \", rand_index, \":\")\n",
    "print(\"Predicted Label: \", prediction)\n",
    "print(\"Actual Label (binary): \", y_test_5[rand_index])\n",
    "print(\"Actual Label (multi-class): \", y_test[rand_index])\n",
    "plt.imshow(X_test[rand_index].reshape(28,28), cmap='Greys')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, it worked!! Or maybe it didn't. Either way, one example from the test set doesn't tell us much, and we isolated 10,000 instances for a reason. Fortunately, we can run predict() on the entire test set and get back an array of 10,000 predicted labels. Using that, we can really evaluate how effective our model is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_5_pred = classifier.predict(X_test)\n",
    "score = accuracy_score(y_test_5, y_test_5_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a great score! Guess our simple model did pretty well on it's own? Not quite.\n",
    "\n",
    "Just because we are doing a binary classification task doesn't mean that our data is split evenly into two classes! In this case, only 10% of the samples are in the 'five' class, and the rest are 'not five', *so a model that spits out [ False ] Every time would have 90% accuracy!*\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "We can't rely on a single metric to evaluate our model. One useful metric is the *Confusion Matrix.* A confusion matrix shows us how many instances are classified correctly and incorrectly for both of our classes. More precisely,\n",
    "\n",
    "$$\\text{confusion matrix} = \\begin{bmatrix} \\text{True Negative} & \\text{False Positive} \\\\ \\text{False Negative} & \\text{True Positive} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8960  148]\n",
      " [ 205  687]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mx = confusion_matrix(y_test_5, y_test_5_pred)\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall\n",
    "\n",
    "Two more useful values we can extract from the confusion matrix are *Precision* and *Recall.*\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "* Precision is the proportion of instances that were correctly labeled as 'True' out of all the 'True' predictions\n",
    "    - How many of our selected items were classified correctly?\n",
    "    - Higher precision => fewer false positives\n",
    "* Recall is the proportion of instances that were correctly labeled as 'True' out of all the instances that actually are 'True'\n",
    "    - How many of the total relevant items did we get?\n",
    "    - Higher recall => fewer false negatives\n",
    "    \n",
    "More formally,\n",
    "\n",
    "$\\text{Precision} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Positive}}}$\n",
    "\n",
    "$\\text{Recall} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Negative}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.822754491018\n",
      "Recall:  0.770179372197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test_5, y_test_5_pred)\n",
    "recall = recall_score(y_test_5, y_test_5_pred)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
