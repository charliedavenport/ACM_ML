{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recognizing Handwritten Digits using Scikit-Learn\n",
    "\n",
    "MNIST dataset: https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "![alt text][img]\n",
    "\n",
    "[img]: https://i.imgur.com/2xVHT7a.png \"not the best handwriting\"\n",
    "\n",
    "* 28x28 (784 pixels total) images of handwritten digits\n",
    "* each image has a label 0-9\n",
    "* ~~70,000~~ 42,000 total images & labels\n",
    "* our goal is to correctly guess the label when we can only see pixel data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fetch the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets # broken - mldata.org is down. Using local csv file for now (sorry!)\n",
    "import pandas as pd\n",
    "from IPython.display import display # pretty tables\n",
    "\n",
    "# mnist = fetch_mldata('MNIST original') # this ridiculously convenient function is broken ;_;\n",
    "mnist = pd.read_csv('../MNIST/train.csv') # only using train, because test has no labels\n",
    "\n",
    "print(mnist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning Rundown\n",
    "\n",
    "\"Machine Learning is the science (and art) of programming computers so they can *learn from data.*\"\n",
    "\n",
    "* Aurélien Géron, *Hands-On Machine Learning with Scikit-Learn & Tensorflow*\n",
    "\n",
    "**Some useful resources**\n",
    "\n",
    "* Scikit-Learn's introduction to machine learning: http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "* MIT OpenCourseWare: https://www.youtube.com/watch?v=h0e2HAPTGF4\n",
    "* kaggle - datasets and ML competitions: https://www.kaggle.com/datasets\n",
    "\n",
    "**Example: Spam-filter**\n",
    "\n",
    "* Learns to flag spam from given examples of spam emails and regular, \"ham\", emails\n",
    "* This set of example emails is called the *training set*\n",
    "* Each email in the training set is called an *instance*\n",
    "* Each instance contains *data* (contents of the email) and a *target* ('spam' or 'ham')\n",
    "* Each point of data within an instance is a *feature*\n",
    "* For training purposes, we separate the data and target\n",
    "\n",
    "**Math notation**\n",
    "\n",
    "* Uppercase Bold = Matrices\n",
    "    * e.g. $\\mathbf{A}$  \n",
    "* Lowercase Bold = Vectors  \n",
    "    * e.g. $\\mathbf{a}$\n",
    "* Italics = Scalars  \n",
    "    * e.g. $a$\n",
    "* Rows are indexed by subscript, Columns by superscript\n",
    "\n",
    "$\\mathbf{X}$ is a matrix containing the data portion of our dataset (no labels)\n",
    "\n",
    "* $\\mathbf{X}$ has $n$ rows (instances) and $m$ columns (features)\n",
    "\n",
    "The i-th row of the matrix, $\\mathbf{x}_i$, is one instance in our dataset.\n",
    "\n",
    "The j-th element of the i-th row is the value of one feature for a given instance, denoted $x_i^j$\n",
    "\n",
    "$\\mathbf{y}$ is the target vector containing a label for each instance \n",
    "\n",
    "The i-th element of the target vector is a label for a single instance, $y_i$\n",
    "\n",
    "* Sometimes our data doesn't have labels. When we have labels for training, it's called *Supervised Learning*. When we don't, it's *Unsupervised Learning.* We'll stick to Supervised Learning for now.\n",
    "\n",
    "Our model is a function, $h$, which takes in an instance, $\\mathbf{x}_i$, and gives us a *Predicted Label*, $\\hat{y_i}$\n",
    "\n",
    "$$\\large{ h(\\mathbf{x}_i) = \\hat{y_i} }$$\n",
    "\n",
    "if $\\hat{y_i} = y_i$, then our model guessed the label perfectly for the i-th instance\n",
    "\n",
    "We can also run our model on all instanes in our dataset in one go:\n",
    "\n",
    "$$\\large{ h(\\mathbf{X}) = \\mathbf{\\hat{y}} }$$\n",
    "\n",
    "In practice, we split the given dataset into a *Training Set* and *Test Set*, so we can evaluate our models after we train them.\n",
    "*It is very important that we do not let our models see the test data during training!* Our goal is not to memorize our data, but to create a model capable of classifyig data it has never seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Separate data and target labels\n",
    "\n",
    "* Pandas dataframe/series documentation: https://pandas.pydata.org/pandas-docs/stable/dsintro.html\n",
    "* iloc takes in positional index (ints) and returns a dataframe or series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (42000, 784)\n",
      "target shape:  (42000,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "data = mnist.iloc[:,1:] # returns a numpy array\n",
    "target = mnist.iloc[:,0]\n",
    "# 784 features (pixels), 42,000 instances (images)\n",
    "print(\"data shape: \", data.shape)\n",
    "print(\"target shape: \", target.shape)\n",
    "print(type(data))\n",
    "print(type(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = data.values # converts to numpy array\n",
    "y = target.values\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "# 37,000 for training, 5,000 for testing\n",
    "X_train, X_test = X[:37000], X[37000:]\n",
    "y_train, y_test = y[:37000], y[37000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Display A Random Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing image  17456\n",
      "Label:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0, X_train.shape[0])\n",
    "print('Showing image ', rand_index)\n",
    "plt.imshow(X_train[rand_index].reshape(28,28), cmap='Greys')\n",
    "# cmap keyword: defines colorspace of image\n",
    "# https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "plt.axis('off')\n",
    "print('Label: ', target[rand_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Binary Classifier\n",
    "\n",
    "Easy starting point. Output is True or False (in the class, or not in the class)\n",
    "\n",
    "In this case, we'll recognize whether a digit is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 4 0 0 7 3 5 3]\n",
      "[False False False False False False False False  True False]\n"
     ]
    }
   ],
   "source": [
    "# First, we need to restructure our labels (no need to modify the data itself)\n",
    "y_train_5 = (y_train == 5) \n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "# let's take a peak at our new training labels\n",
    "print(y_train[0:10])   # multiclass\n",
    "print(y_train_5[0:10]) # binary\n",
    "# now, instead of digits 0-9, we have 0's for 'not 5' and 1's for '5' - Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "* list of classification models: http://scikit-learn.org/stable/supervised_learning.html\n",
    "* To start, we will use a SGDClassifier http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "    - SGD is the name of the training algorithm, \"Stochastic Gradient Descent.\" We'll learn much more about Gradient Descent soon!\n",
    "    - This is a linear model, meaning it finds linear boundaries between classes (remember, our classes to start out with are 'five' and 'not five')\n",
    "    - The main reason I've selected this model is that it's simplicity allows for much faster training on our high-dimensional dataset. The trade-off is that it will be less accurate than more complex models.\n",
    "* To train models in sklearn, we only have to call the fit() function and pass in our data and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# there are many parameters we can set here, but they all have default values, so we can safely leave this blank for now\n",
    "classifier = SGDClassifier() \n",
    "classifier.fit(X_train, y_train_5) # This line alone trains the model. We need to pass in the data and labels\n",
    "# We'll implement our own fit() function soon!\n",
    "\n",
    "# ignore the warning - the default parameters for this class work fine for our purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Making a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index  4079 :\n",
      "Predicted Label:  [False]\n",
      "Actual Label (binary):  False\n",
      "Actual Label (multi-class):  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rand_index = np.random.randint(0, 5000)\n",
    "# once the model has been trained, we only have to call the predict() function!\n",
    "prediction = classifier.predict([X_test[rand_index]]) # pass in a random row from X_test\n",
    "\n",
    "print(\"Index \", rand_index, \":\")\n",
    "print(\"Predicted Label: \", prediction)\n",
    "print(\"Actual Label (binary): \", y_test_5[rand_index])\n",
    "print(\"Actual Label (multi-class): \", y_test[rand_index])\n",
    "\n",
    "plt.imshow(X_test[rand_index].reshape(28,28), cmap='Greys')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Wow, it worked!! Or maybe it didn't. Either way, one example from the test set doesn't tell us much, and we isolated 5,000 instances for a reason. Fortunately, we can run predict() on the entire test set and get back an array of 5,000 predicted labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_5_pred = classifier.predict(X_test) # pass in the entire test set\n",
    "score = accuracy_score(y_test_5, y_test_5_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Wow, that's a great score! Guess our simple model did pretty well on it's own? Not necessarily.\n",
    "\n",
    "Just because we are doing a binary classification task doesn't mean that our data is split evenly into two classes! In this case, only 10% of the samples are in the 'five' class, and the rest are 'not five', so a \"dumb\" model that just spits out [ False ] Every time would have *90% accuracy!*\n",
    "\n",
    "This is called *Label Imbalance*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "We can't rely on a single metric to evaluate our model. The *Confusion Matrix* is a useful tool for evaluation, because it shows us how many instances are classified correctly and incorrectly for both of our classes. More precisely,\n",
    "\n",
    "$$\\text{confusion matrix} = \\begin{bmatrix} \\text{True Negative} & \\text{False Positive} \\\\ \\text{False Negative} & \\text{True Positive} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4508   77]\n",
      " [  75  340]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mx = confusion_matrix(y_test_5, y_test_5_pred)\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Precision and Recall\n",
    "\n",
    "Two more useful values we can extract from the confusion matrix are *Precision* and *Recall.*\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "* Precision is the proportion of instances that were correctly labeled as 'True' out of all the 'True' predictions\n",
    "    - How many of our selected items were classified correctly?\n",
    "    - Higher precision => fewer false positives\n",
    "* Recall is the proportion of instances that were correctly labeled as 'True' out of all the instances that actually are 'True'\n",
    "    - How many of the total relevant items did we get?\n",
    "    - Higher recall => fewer false negatives\n",
    "    \n",
    "More formally,\n",
    "\n",
    "$\\text{Precision} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Positive}}}$\n",
    "\n",
    "$\\text{Recall} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Negative}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.815347721822542\n",
      "Recall:  0.8192771084337349\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test_5, y_test_5_pred)\n",
    "recall = recall_score(y_test_5, y_test_5_pred)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charlie/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_clf = SGDClassifier()\n",
    "multi_clf.fit(X_train, y_train) # same data, different labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accuracy, Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8746\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>506</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>403</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>453</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>328</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>473</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>441</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9\n",
       "0  506    0    0    0    0    0    3    0   11    0\n",
       "1    0  542    0    1    1    1    1    0   16    1\n",
       "2    4    2  403   11    1    0    4    3   35    2\n",
       "3    2    4   27  419    1   23    3    3   45    3\n",
       "4    6    8    5    0  453    1    6    0   32   10\n",
       "5    4    3    3   10    5  328   13    1   40    8\n",
       "6    6    1    6    0    2    3  473    0    3    0\n",
       "7    2    4   12    3    9    5    0  441    7   23\n",
       "8    3   21    6    4    7    7    2    0  435    0\n",
       "9    8    7    5    5   50   10    0   18   25  373"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_pred = multi_clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "conf_mx = confusion_matrix(y_test, y_test_pred) # what does the confusion matrix look like for multiclass predictions?\n",
    "\n",
    "print(acc) # How is this accuracy score different from the binary accuracy score? \n",
    "           # Is it a better or worse measure of performance?\n",
    "display(pd.DataFrame(conf_mx)) # convert to dataframe so it prints with indices, use display() to make it pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAAmCAYAAAAsspvsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAAcpJREFUeJzt3Mtu1EAQBdB+ODMJBAgg8f8/GF4CEkBhWETyVLdsxAKRRZ2zqumqtlvWzJU3ST2dTgWAXNpTHwCA/0/4AyQk/AESEv4ACQl/gISEP0BCwh8gIeEPkJDwB0hoeeoD7Km1rn96/K5cD70X5e1aH0PvMqyXUspF6B3Km1C/HuaW8jzsuVnrHtYfe6/CnpdDr5er0LsO65fjveqztW7lGPaMc3Ffr0tYvxjmWulhLtSljnPhYx/Wf033fQi9c93rz+m+38Pc2Ov1bq1r/RHWv05n+hLq+zD3eZir9VvofTrvaR+nufP1e/uwuf647/32GdrtNHe7Pdfvhrkanm3rQ6u0tlNPc3vXqNPrWVu259o0V/vO3PIP5kKvjl/H8ezzNeLZw746P7PQa4c/zMVePNPh7+bacZwbrnHcXp/3tfCznZ/FcI35OcV9sZ7PvtOrV9PcsO80/vh3ePMHSEj4AyQk/AESqv6rJ0A+3vwBEhL+AAkJf4CEhD9AQsIfICHhD5CQ8AdISPgDJCT8ARIS/gAJCX+AhIQ/QELCHyAh4Q+QkPAHSEj4AyQk/AESEv4ACQl/gISEP0BCwh8gIeEPkJDwB0joN2q+IkdtXZdzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show color map for reference\n",
    "plt.imshow(np.arange(0, 1, 0.01).reshape(1,-1), cmap = 'gnuplot')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Display confusion matrix as an image\n",
    "plt.imshow(conf_mx, cmap = 'gnuplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Precision and Recall for Multiclass Predictions\n",
    "\n",
    "**TODO:** explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg):  0.8822243562661052\n",
      "Recall (weighted avg):  0.8746\n",
      "Precision (simple avg):  0.8804145720959248\n",
      "Recall (simple avg):  0.8723302236535163\n"
     ]
    }
   ],
   "source": [
    "precision_weighted = precision_score(y_test, y_test_pred, average=\"weighted\")\n",
    "recall_weighted = recall_score(y_test, y_test_pred, average=\"weighted\")\n",
    "precision_macro = precision_score(y_test, y_test_pred, average=\"macro\")\n",
    "recall_macro = recall_score(y_test, y_test_pred, average=\"macro\")\n",
    "\n",
    "print(\"Precision (weighted avg): \", precision_weighted)\n",
    "print(\"Recall (weighted avg): \", recall_weighted)\n",
    "print(\"Precision (simple avg): \", precision_macro)\n",
    "print(\"Recall (simple avg): \", recall_macro)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
