{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognizing Handwritten Digits using Scikit-Learn\n",
    "\n",
    "MNIST dataset: https://en.wikipedia.org/wiki/MNIST_database\n",
    "\n",
    "* 28x28 (784 pixels total) images of handwritten digits\n",
    "* each image has a label 0-9\n",
    "* ~~70,000~~ 42,000 total images & labels\n",
    "* our goal is to correctly guess the label when we can only see pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "mnist = pd.read_csv('../MNIST/train.csv') # only using train, because test has no labels\n",
    "\n",
    "print(mnist.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Rundown\n",
    "\n",
    "\"Machine Learning is the science (and art) of programming computers so they can *learn from data.*\"\n",
    "\n",
    "* Aurélien Géron, *Hands-On Machine Learning with Scikit-Learn & Tensorflow*\n",
    "\n",
    "**Some useful resources**\n",
    "\n",
    "* Scikit-Learn's introduction to machine learning: http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "* MIT OpenCourseWare: https://www.youtube.com/watch?v=h0e2HAPTGF4\n",
    "* kaggle - datasets and ML competitions: https://www.kaggle.com/datasets\n",
    "\n",
    "**Example: Spam-filter**\n",
    "\n",
    "* Learns to flag spam from given examples of spam emails and regular, \"ham\", emails\n",
    "* This set of example emails is called the *training set*\n",
    "* Each email in the training set is called an *instance*\n",
    "* Each instance contains *data* (contents of the email) and a *target* ('spam' or 'ham')\n",
    "* Each point of data within an instance is a *feature*\n",
    "* For training purposes, we separate the data and target\n",
    "\n",
    "**Math notation**\n",
    "\n",
    "* Uppercase Bold = matrices\n",
    "* lowercase bold = vectors\n",
    "* Italics = scalars\n",
    "* Rows are indexed by subscript, Columns by superscript\n",
    "\n",
    "$\\mathbf{X}$ is a matrix containing the data portion of our dataset (no labels)\n",
    "\n",
    "* $\\mathbf{X}$ has $n$ rows (instances) and $m$ columns (features)\n",
    "\n",
    "The i-th row of the matrix, $\\mathbf{x}_i$, is one instance in our dataset.\n",
    "\n",
    "The j-th element of the i-th row is the value of one feature for a given instance, denoted $x_i^j$\n",
    "\n",
    "$\\mathbf{y}$ is the target vector containing a label for each instance \n",
    "\n",
    "The i-th element of the target vector is a label for a single instance, $y_i$\n",
    "\n",
    "* Sometimes our data doesn't have labels. When we have labels for training, it's called *Supervised Learning*. When we don't, it's *Unsupervised Learning.* We'll stick to Supervised Learning for now.\n",
    "\n",
    "Our model is a function, $h$, which takes in an instance, $\\mathbf{x}_i$, and gives us a *Predicted Label*, $\\hat{y_i}$\n",
    "\n",
    "$$\\large{ h(\\mathbf{x}_i) = \\hat{y_i} }$$\n",
    "\n",
    "if $\\hat{y_i} = y_i$, then our model guessed the label perfectly for the i-th instance\n",
    "\n",
    "We can also run our model on all instanes in our dataset in one go:\n",
    "\n",
    "$$\\large{ h(\\mathbf{X}) = \\mathbf{\\hat{y}} }$$\n",
    "\n",
    "In practice, we split the given dataset into a *Training Set* and *Test Set*, so we can evaluate our models after we train them.\n",
    "*It is very important that we do not let our models see the test data during training!* Our goal is not to memorize our data, but to create a model capable of classifyig data it has never seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate data and target labels\n",
    "\n",
    "* Pandas dataframe/series documentation: https://pandas.pydata.org/pandas-docs/stable/dsintro.html\n",
    "* iloc takes in positional index (ints) and returns a dataframe or series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (42000, 784)\n",
      "target shape:  (42000,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "data = mnist.iloc[:,1:] # returns a numpy array\n",
    "target = mnist.iloc[:,0]\n",
    "# 784 features (pixels), 42,000 instances (images)\n",
    "print(\"data shape: \", data.shape)\n",
    "print(\"target shape: \", target.shape)\n",
    "print(type(data))\n",
    "print(type(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>   <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = data.values # converts to numpy array\n",
    "y = target.values\n",
    "print(type(X), \" \", type(y))\n",
    "# 37,000 for training, 5,000 for testing\n",
    "X_train, X_test = X[:37000], X[37000:]\n",
    "y_train, y_test = y[:37000], y[37000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display A Random Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = np.random.randint(0, X_train.shape[0])\n",
    "print('Showing image ', rand_index)\n",
    "plt.imshow(X_train[rand_index].reshape(28,28), cmap='Greys')\n",
    "plt.axis('off')\n",
    "print('Label: ', target[rand_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classifier\n",
    "\n",
    "Easy starting point. Output is True or False (in the class, or not in the class)\n",
    "\n",
    "In this case, we'll recognize whether a digit is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to restructure our labels\n",
    "y_train_5 = (y_train == 5) \n",
    "y_test_5 = (y_test == 5)\n",
    "# now, instead of digits 0-9, we have 0's for 'not 5' and 1's for '5' - Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "* list of classification models: http://scikit-learn.org/stable/supervised_learning.html\n",
    "* To start, we will use a SGDClassifier http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "    - SGD is the name of the training algorithm, \"Stochastic Gradient Descent.\" We'll learn much more about Gradient Descent algorithms soon!\n",
    "    - This is a linear model, meaning it finds linear boundaries between classes (remember, our classes to start out with are 'five' and 'not five')\n",
    "    - The main reason I've selected this model is that it's simplicity allows for much faster training on our high-dimensional dataset. The trade-off is that it will be less accurate than more complex models.\n",
    "* To train models in sklearn, we only have to call the fit() function and pass in our data and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# there are many parameters we can set here, but they all have default values, so we can safely leave this blank\n",
    "classifier = SGDClassifier() \n",
    "classifier.fit(X_train, y_train_5) # This line alone trains the model. \n",
    "# We'll go over how to implement our own fit() function soon!\n",
    "\n",
    "# ignore the warning - the default parameters for this class work fine for our purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = np.random.randint(0, 5000)\n",
    "# once the model has been trained, we only have to call the predict() function!\n",
    "prediction = classifier.predict([X_test[rand_index]])\n",
    "print(\"Sample \", rand_index, \":\")\n",
    "print(\"Predicted Label: \", prediction)\n",
    "print(\"Actual Label (binary): \", y_test_5[rand_index])\n",
    "print(\"Actual Label (multi-class): \", y_test[rand_index])\n",
    "plt.imshow(X_test[rand_index].reshape(28,28), cmap='Greys')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, it worked!! Or maybe it didn't. Either way, one example from the test set doesn't tell us much, and we isolated 5,000 instances for a reason. Fortunately, we can run predict() on the entire test set and get back an array of 5,000 predicted labels. Using that, we can really evaluate how effective our model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_5_pred = classifier.predict(X_test)\n",
    "score = accuracy_score(y_test_5, y_test_5_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that's a great score! Guess our simple model did pretty well on it's own? Not quite.\n",
    "\n",
    "Just because we are doing a binary classification task doesn't mean that our data is split evenly into two classes! In this case, only 10% of the samples are in the 'five' class, and the rest are 'not five', *so a model that spits out [ False ] Every time would have 90% accuracy!*\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "We can't rely on a single metric to evaluate our model. One useful metric is the *Confusion Matrix.* A confusion matrix shows us how many instances are classified correctly and incorrectly for both of our classes. More precisely,\n",
    "\n",
    "$$\\text{confusion matrix} = \\begin{bmatrix} \\text{True Negative} & \\text{False Positive} \\\\ \\text{False Negative} & \\text{True Positive} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mx = confusion_matrix(y_test_5, y_test_5_pred)\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision and Recall\n",
    "\n",
    "Two more useful values we can extract from the confusion matrix are *Precision* and *Recall.*\n",
    "\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "* Precision is the proportion of instances that were correctly labeled as 'True' out of all the 'True' predictions\n",
    "    - How many of our selected items were classified correctly?\n",
    "    - Higher precision => fewer false positives\n",
    "* Recall is the proportion of instances that were correctly labeled as 'True' out of all the instances that actually are 'True'\n",
    "    - How many of the total relevant items did we get?\n",
    "    - Higher recall => fewer false negatives\n",
    "    \n",
    "More formally,\n",
    "\n",
    "$\\text{Precision} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Positive}}}$\n",
    "\n",
    "$\\text{Recall} = \\large{\\frac{\\text{True Positive}}{\\text{True Positive + False Negative}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test_5, y_test_5_pred)\n",
    "recall = recall_score(y_test_5, y_test_5_pred)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
